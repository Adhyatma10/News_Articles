{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Popularity Class and Value for an Article in Facebook, GooglePlus, LinkedIn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ADHYATMA SHARMA\\anaconda3\\envs\\personaluse\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying articles into High, Low and Average Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Cleaned data after running the ETL file:\n",
    "data=pd.read_csv(\"Cleaned_News.csv\")\n",
    "data['PublishDate'] = pd.to_datetime(data['PublishDate'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Columns out of PublishDate and Sentiment Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new Columns \n",
    "def create_derived_features(df):\n",
    "    \"\"\"Creates derived features from existing columns.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame containing news data with 'SentimentTitle',\n",
    "            'SentimentHeadline', and 'PublishDate' columns.\n",
    "\n",
    "    Returns:\n",
    "        A new Pandas DataFrame with the derived features, or the original\n",
    "        DataFrame if the required columns are missing. Returns None if input is not a dataframe.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Input is not a Pandas DataFrame\")\n",
    "        return None\n",
    "    df_derived = df.copy()\n",
    "\n",
    "    required_cols = ['SentimentTitle', 'SentimentHeadline', 'PublishDate']\n",
    "    if not all(col in df_derived.columns for col in required_cols):\n",
    "        print(f\"Missing required columns: {set(required_cols) - set(df_derived.columns)}\")\n",
    "        return df_derived  # Return original if columns are missing\n",
    "\n",
    "    # 1. Sentiment Mean\n",
    "    df_derived['Sentiment_mean'] = df_derived[['SentimentTitle', 'SentimentHeadline']].mean(axis=1)\n",
    "\n",
    "    # 2. Publish Day\n",
    "    df_derived['PublishDay'] = df_derived['PublishDate'].dt.day_name()\n",
    "\n",
    "    # 3. Publish Hour\n",
    "    df_derived['PublishHour'] = df_derived['PublishDate'].dt.hour\n",
    "\n",
    "    # 4. Time of Day\n",
    "    def categorize_time(hour):\n",
    "        if 6 <= hour < 12:\n",
    "            return 'Morning'\n",
    "        elif 12 <= hour < 17:\n",
    "            return 'Afternoon'\n",
    "        elif 17 <= hour < 21:\n",
    "            return 'Evening'\n",
    "        else:\n",
    "            return 'Night'\n",
    "\n",
    "    df_derived['TimeOfDay'] = df_derived['PublishHour'].apply(categorize_time)\n",
    "\n",
    "    return df_derived\n",
    "\n",
    "data = create_derived_features(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IDLink', 'Title', 'Headline', 'Source', 'Topic', 'PublishDate',\n",
       "       'SentimentTitle', 'SentimentHeadline', 'Facebook', 'GooglePlus',\n",
       "       'LinkedIn', 'Sentiment_mean', 'PublishDay', 'PublishHour', 'TimeOfDay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will no create the Target columns that would be based upon the Quartile ranges of our Continous Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDLink</th>\n",
       "      <th>Title</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Topic</th>\n",
       "      <th>PublishDate</th>\n",
       "      <th>SentimentTitle</th>\n",
       "      <th>SentimentHeadline</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Sentiment_mean</th>\n",
       "      <th>PublishDay</th>\n",
       "      <th>PublishHour</th>\n",
       "      <th>TimeOfDay</th>\n",
       "      <th>facebook_class</th>\n",
       "      <th>googleplus_class</th>\n",
       "      <th>linkedin_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99248</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
       "      <td>USA TODAY</td>\n",
       "      <td>obama</td>\n",
       "      <td>2002-04-02 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053300</td>\n",
       "      <td>2547.659722</td>\n",
       "      <td>1538.570833</td>\n",
       "      <td>499.025000</td>\n",
       "      <td>-0.026650</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10423</td>\n",
       "      <td>A Look at the Health of the Chinese Economy</td>\n",
       "      <td>Tim Haywood investment director businessunit h...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>economy</td>\n",
       "      <td>2008-09-20 00:00:00</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>-0.156386</td>\n",
       "      <td>1380.145833</td>\n",
       "      <td>1957.444444</td>\n",
       "      <td>753.729167</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18828</td>\n",
       "      <td>Nouriel Roubini Global Economy Not Back to 2008</td>\n",
       "      <td>Nouriel Roubini NYU professor and chairman at ...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>economy</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "      <td>-0.425210</td>\n",
       "      <td>0.139754</td>\n",
       "      <td>1647.295833</td>\n",
       "      <td>2242.472222</td>\n",
       "      <td>874.993056</td>\n",
       "      <td>-0.142728</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27788</td>\n",
       "      <td>Finland GDP Expands In Q4</td>\n",
       "      <td>Finlands economy expanded marginally in the th...</td>\n",
       "      <td>RTT News</td>\n",
       "      <td>economy</td>\n",
       "      <td>2015-03-01 00:06:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>1157.554167</td>\n",
       "      <td>1805.383333</td>\n",
       "      <td>701.736111</td>\n",
       "      <td>0.013032</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27789</td>\n",
       "      <td>Tourism govt spending buoys Thai economy in Ja...</td>\n",
       "      <td>Tourism and public spending continued to boost...</td>\n",
       "      <td>The Nation Thailand39s English news</td>\n",
       "      <td>economy</td>\n",
       "      <td>2015-03-01 00:11:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141084</td>\n",
       "      <td>1439.512500</td>\n",
       "      <td>2166.450000</td>\n",
       "      <td>857.687500</td>\n",
       "      <td>0.070542</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDLink                                              Title  \\\n",
       "0   99248   Obama Lays Wreath at Arlington National Cemetery   \n",
       "1   10423        A Look at the Health of the Chinese Economy   \n",
       "2   18828    Nouriel Roubini Global Economy Not Back to 2008   \n",
       "3   27788                          Finland GDP Expands In Q4   \n",
       "4   27789  Tourism govt spending buoys Thai economy in Ja...   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  Obama Lays Wreath at Arlington National Cemete...   \n",
       "1  Tim Haywood investment director businessunit h...   \n",
       "2  Nouriel Roubini NYU professor and chairman at ...   \n",
       "3  Finlands economy expanded marginally in the th...   \n",
       "4  Tourism and public spending continued to boost...   \n",
       "\n",
       "                                Source    Topic         PublishDate  \\\n",
       "0                            USA TODAY    obama 2002-04-02 00:00:00   \n",
       "1                            Bloomberg  economy 2008-09-20 00:00:00   \n",
       "2                            Bloomberg  economy 2012-01-28 00:00:00   \n",
       "3                             RTT News  economy 2015-03-01 00:06:00   \n",
       "4  The Nation Thailand39s English news  economy 2015-03-01 00:11:00   \n",
       "\n",
       "   SentimentTitle  SentimentHeadline     Facebook   GooglePlus    LinkedIn  \\\n",
       "0        0.000000          -0.053300  2547.659722  1538.570833  499.025000   \n",
       "1        0.208333          -0.156386  1380.145833  1957.444444  753.729167   \n",
       "2       -0.425210           0.139754  1647.295833  2242.472222  874.993056   \n",
       "3        0.000000           0.026064  1157.554167  1805.383333  701.736111   \n",
       "4        0.000000           0.141084  1439.512500  2166.450000  857.687500   \n",
       "\n",
       "   Sentiment_mean PublishDay  PublishHour TimeOfDay  facebook_class  \\\n",
       "0       -0.026650    Tuesday            0     Night               2   \n",
       "1        0.025974   Saturday            0     Night               1   \n",
       "2       -0.142728   Saturday            0     Night               1   \n",
       "3        0.013032     Sunday            0     Night               0   \n",
       "4        0.070542     Sunday            0     Night               1   \n",
       "\n",
       "   googleplus_class  linkedin_class  \n",
       "0                 1               0  \n",
       "1                 1               1  \n",
       "2                 2               1  \n",
       "3                 1               1  \n",
       "4                 2               1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify_columns(data):\n",
    "    for platform in ['Facebook', 'GooglePlus', 'LinkedIn']:\n",
    "        # Determine the column's quartiles\n",
    "        q25 = data[platform].quantile(0.25)\n",
    "        q75 = data[platform].quantile(0.75)\n",
    "        \n",
    "        # Create a new column based on the quartile ranges\n",
    "        data[f'{platform.lower()}_class'] = pd.cut(\n",
    "            data[platform],\n",
    "            bins=[-float('inf'), q25, q75, float('inf')],\n",
    "            labels=[0, 1, 2],\n",
    "            include_lowest=True\n",
    "        ).astype(int)\n",
    "    \n",
    "    return data\n",
    "\n",
    "df = classify_columns(data)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IDLink', 'Title', 'Headline', 'Source', 'Topic', 'PublishDate',\n",
       "       'SentimentTitle', 'SentimentHeadline', 'Sentiment_mean', 'PublishDay',\n",
       "       'PublishHour', 'TimeOfDay', 'facebook_class', 'googleplus_class',\n",
       "       'linkedin_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the Continous target Variables for sound model:\n",
    "df=df.drop([\"Facebook\",\"GooglePlus\",\"LinkedIn\"],axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model For Facebook_Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing for facebook_class...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.81      4664\n",
      "           1       0.83      0.86      0.85      9322\n",
      "           2       0.88      0.88      0.88      4662\n",
      "\n",
      "    accuracy                           0.84     18648\n",
      "   macro avg       0.85      0.84      0.84     18648\n",
      "weighted avg       0.84      0.84      0.84     18648\n",
      "\n",
      "Accuracy Score: 0.8442192192192193\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "1. Sentiment_mean (0.2911)\n",
      "2. Topic_obama (0.2621)\n",
      "3. Source_freq (0.1953)\n",
      "4. PublishHour (0.1152)\n",
      "5. Topic_palestine (0.0521)\n",
      "6. Topic_microsoft (0.0263)\n",
      "7. TimeOfDay_Night (0.0138)\n",
      "8. PublishDay_Sunday (0.0099)\n",
      "9. TimeOfDay_Morning (0.0090)\n",
      "10. PublishDay_Saturday (0.0053)\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess data\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesses the data for modeling.\n",
    "    - Encodes categorical variables.\n",
    "    - Scales numerical features.\n",
    "    - Encodes the 'Source' column using frequency encoding.\n",
    "    \"\"\"\n",
    "    # Work on a copy of the DataFrame to avoid altering the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Frequency encoding for 'Source'\n",
    "    source_freq = df_copy['Source'].value_counts(normalize=True)  # Normalize for proportion-based encoding\n",
    "    df_copy['Source_freq'] = df_copy['Source'].map(source_freq)\n",
    "    df_copy.drop(columns=['Source'], inplace=True)  # Drop original Source column\n",
    "\n",
    "    # One-hot encode other categorical features\n",
    "    categorical_cols = ['Topic', 'PublishDay', 'TimeOfDay']\n",
    "    df_encoded = pd.get_dummies(df_copy, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Scaling numerical columns\n",
    "    numerical_cols = ['Sentiment_mean']\n",
    "    scaler = StandardScaler()\n",
    "    df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "# Function to split data\n",
    "def split_data(df, target_col):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets.\n",
    "    - df: DataFrame\n",
    "    - target_col: Target column name\n",
    "    \"\"\"\n",
    "    X = df.drop(columns=[target_col, 'IDLink', 'Title', 'Headline', \"PublishDate\", \"googleplus_class\", \"linkedin_class\",\"SentimentHeadline\",\"SentimentTitle\"])\n",
    "    y = df[target_col]\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest model.\n",
    "    - Returns the trained model.\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to evaluate a model and print feature importance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set and prints feature importance.\n",
    "    - Prints classification report, accuracy, and top features.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Print feature importances (if the model has a feature_importances_ attribute)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        feature_names = list(X_test.columns)\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        # Print top 10 most important features\n",
    "        print(\"\\nTop 10 Most Important Features:\")\n",
    "        for i, idx in enumerate(sorted_indices[:10]):\n",
    "            print(f\"{i+1}. {feature_names[idx]} ({importances[idx]:.4f})\")\n",
    "\n",
    "\n",
    "# Main function to process the pipeline\n",
    "def main_pipeline(df, target_col):\n",
    "    \"\"\"\n",
    "    End-to-end pipeline for preprocessing, training, and evaluation.\n",
    "    - df: DataFrame\n",
    "    - target_col: Target column for prediction\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing for {target_col}...\")\n",
    "    df_preprocessed = preprocess_data(df)\n",
    "    X_train, X_test, y_train, y_test = split_data(df_preprocessed, target_col)\n",
    "    model = train_model(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Call pipeline for each platform (assuming your data has columns for facebook, googleplus, linkedin classification)\n",
    "facebook_model = main_pipeline(df, 'facebook_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs provide an evaluation of the classifier's performance on the `facebook_class` target variable, with the following metrics:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Classification Report**\n",
    "\n",
    "This report includes metrics for each class (0, 1, and 2) in the target variable:\n",
    "\n",
    "#### **Precision**\n",
    "\n",
    "-   Precision measures how many of the predicted positive instances for a class are actually correct.\n",
    "-   Formula: Precision = True Positives / (True Positives + False Positives)\n",
    "-   High precision indicates that the model has low false positive rates.\n",
    "\n",
    "-   **Class 0**: \\( 0.83 \\) (83% of samples predicted as class 0 are actually class 0.)\n",
    "-   **Class 1**: \\( 0.83 \\) (83% of samples predicted as class 1 are actually class 1.)\n",
    "-   **Class 2**: \\( 0.88 \\) (88% of samples predicted as class 2 are actually class 2.)\n",
    "\n",
    "#### **Recall**\n",
    "\n",
    "-   Recall measures how many of the actual positive instances for a class the model correctly identified.\n",
    "-   Formula: Recall = True Positives / (False Negatives + True Positives)\n",
    "-   High recall indicates that the model has low false negative rates.\n",
    "\n",
    "-   **Class 0**: \\( 0.78 \\) (78% of actual class 0 samples were correctly identified.)\n",
    "-   **Class 1**: \\( 0.86 \\) (86% of actual class 1 samples were correctly identified.)\n",
    "-   **Class 2**: \\( 0.88 \\) (88% of actual class 2 samples were correctly identified.)\n",
    "\n",
    "#### **F1-Score**\n",
    "\n",
    "-   F1-Score is the harmonic mean of precision and recall, providing a single score that balances both metrics.\n",
    "-   Formula: F1-Score = 2 \\* ((Precision \\* Recall) / (Precision + Recall))\n",
    "-   A high F1-Score indicates the model is performing well in both precision and recall.\n",
    "\n",
    "-   **Class 0**: \\( 0.81 \\)\n",
    "-   **Class 1**: \\( 0.85 \\)\n",
    "-   **Class 2**: \\( 0.88 \\)\n",
    "\n",
    "#### **Support**\n",
    "\n",
    "-   Support refers to the number of samples in each class in the test dataset.\n",
    "-   **Class 0**: \\( 4664 \\)\n",
    "-   **Class 1**: \\( 9322 \\)\n",
    "-   **Class 2**: \\( 4662 \\)\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Overall Metrics**\n",
    "\n",
    "#### **Accuracy**\n",
    "\n",
    "-   Accuracy is the ratio of correctly predicted samples to the total number of samples.\n",
    "-   **Result**: \\( 0.844 \\) (The model correctly predicted 84.4% of the samples.)\n",
    "\n",
    "#### **Macro Average**\n",
    "\n",
    "-   The unweighted mean of precision, recall, and F1-Score across all classes.\n",
    "-   Treats all classes equally, regardless of their support.\n",
    "\n",
    "-   **Macro Precision**: \\( 0.85 \\)\n",
    "-   **Macro Recall**: \\( 0.84 \\)\n",
    "-   **Macro F1-Score**: \\( 0.84 \\)\n",
    "\n",
    "#### **Weighted Average**\n",
    "\n",
    "-   The weighted mean of precision, recall, and F1-Score across all classes.\n",
    "-   Weights each class’s metric by its support, giving more importance to classes with more samples.\n",
    "\n",
    "-   **Weighted Precision**: \\( 0.84 \\)\n",
    "-   **Weighted Recall**: \\( 0.84 \\)\n",
    "-   **Weighted F1-Score**: \\( 0.84 \\)\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "\n",
    "1.  **Good Performance**: The model has a good overall accuracy of 84.4% and reasonable F1-Scores for all classes, particularly strong for class 2.\n",
    "2.  **Relatively Balanced Metrics**: The precision and recall scores are reasonably balanced across the classes, suggesting that the model is not significantly biased towards any particular class.\n",
    "3.  **Class Distribution Impact**: The weighted average scores are very close to the macro averages, indicating that the class distribution is relatively balanced and does not significantly skew the overall performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model for GooglePlus_Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing for googleplus_class...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78      4663\n",
      "           1       0.80      0.82      0.81      9323\n",
      "           2       0.83      0.82      0.83      4662\n",
      "\n",
      "    accuracy                           0.81     18648\n",
      "   macro avg       0.81      0.80      0.80     18648\n",
      "weighted avg       0.81      0.81      0.81     18648\n",
      "\n",
      "Accuracy Score: 0.8052874302874303\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "1. PublishHour (0.2598)\n",
      "2. Sentiment_mean (0.2457)\n",
      "3. Source_freq (0.1786)\n",
      "4. Topic_obama (0.1348)\n",
      "5. Topic_microsoft (0.0659)\n",
      "6. Topic_palestine (0.0587)\n",
      "7. TimeOfDay_Night (0.0171)\n",
      "8. TimeOfDay_Morning (0.0107)\n",
      "9. TimeOfDay_Evening (0.0082)\n",
      "10. PublishDay_Tuesday (0.0038)\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess data\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesses the data for modeling.\n",
    "    - Encodes categorical variables.\n",
    "    - Scales numerical features.\n",
    "    - Encodes the 'Source' column using frequency encoding.\n",
    "    \"\"\"\n",
    "    # Work on a copy of the DataFrame to avoid altering the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Frequency encoding for 'Source'\n",
    "    source_freq = df_copy['Source'].value_counts(normalize=True)  # Normalize for proportion-based encoding\n",
    "    df_copy['Source_freq'] = df_copy['Source'].map(source_freq)\n",
    "    df_copy.drop(columns=['Source'], inplace=True)  # Drop original Source column\n",
    "\n",
    "    # One-hot encode other categorical features\n",
    "    categorical_cols = ['Topic', 'PublishDay', 'TimeOfDay']\n",
    "    df_encoded = pd.get_dummies(df_copy, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Scaling numerical columns\n",
    "    numerical_cols = ['Sentiment_mean']\n",
    "    scaler = StandardScaler()\n",
    "    df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "# Function to split data\n",
    "def split_data(df, target_col):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets.\n",
    "    - df: DataFrame\n",
    "    - target_col: Target column name\n",
    "    \"\"\"\n",
    "    X = df.drop(columns=[target_col, 'IDLink', 'Title', 'Headline', \"PublishDate\", \"facebook_class\", \"linkedin_class\",\"SentimentHeadline\",\"SentimentTitle\"])\n",
    "    y = df[target_col]\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest model.\n",
    "    - Returns the trained model.\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to evaluate a model and print feature importance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set and prints feature importance.\n",
    "    - Prints classification report, accuracy, and top features.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Print feature importances (if the model has a feature_importances_ attribute)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        feature_names = list(X_test.columns)\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        # Print top 10 most important features\n",
    "        print(\"\\nTop 10 Most Important Features:\")\n",
    "        for i, idx in enumerate(sorted_indices[:10]):\n",
    "            print(f\"{i+1}. {feature_names[idx]} ({importances[idx]:.4f})\")\n",
    "\n",
    "\n",
    "# Main function to process the pipeline\n",
    "def main_pipeline(df, target_col):\n",
    "    \"\"\"\n",
    "    End-to-end pipeline for preprocessing, training, and evaluation.\n",
    "    - df: DataFrame\n",
    "    - target_col: Target column for prediction\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing for {target_col}...\")\n",
    "    df_preprocessed = preprocess_data(df)\n",
    "    X_train, X_test, y_train, y_test = split_data(df_preprocessed, target_col)\n",
    "    model = train_model(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    return model\n",
    "googleplus_model = main_pipeline(df, 'googleplus_class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs provide an evaluation of the classifier's performance on the `googleplus_class` target variable, with the following metrics:\n",
    "\n",
    "---\n",
    "### GooglePlus Classification Model Evaluation\n",
    "\n",
    "The following metrics summarize the performance of the GooglePlus classification model on the test dataset:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Classification Report**\n",
    "\n",
    "This report includes metrics for each class (0, 1, and 2) in the target variable:\n",
    "\n",
    "#### **Precision**\n",
    "\n",
    "-   Precision measures how many of the predicted positive instances for a class are actually correct.\n",
    "-   Formula: Precision = True Positives / (True Positives + False Positives)\n",
    "-   High precision indicates that the model has low false positive rates.\n",
    "\n",
    "-   **Class 0**: \\( 0.80 \\) (80% of samples predicted as class 0 are actually class 0.)\n",
    "-   **Class 1**: \\( 0.80 \\) (80% of samples predicted as class 1 are actually class 1.)\n",
    "-   **Class 2**: \\( 0.83 \\) (83% of samples predicted as class 2 are actually class 2.)\n",
    "\n",
    "#### **Recall**\n",
    "\n",
    "-   Recall measures how many of the actual positive instances for a class the model correctly identified.\n",
    "-   Formula: Recall = True Positives / (False Negatives + True Positives)\n",
    "-   High recall indicates that the model has low false negative rates.\n",
    "\n",
    "-   **Class 0**: \\( 0.76 \\) (76% of actual class 0 samples were correctly identified.)\n",
    "-   **Class 1**: \\( 0.82 \\) (82% of actual class 1 samples were correctly identified.)\n",
    "-   **Class 2**: \\( 0.82 \\) (82% of actual class 2 samples were correctly identified.)\n",
    "\n",
    "#### **F1-Score**\n",
    "\n",
    "-   F1-Score is the harmonic mean of precision and recall, providing a single score that balances both metrics.\n",
    "-   Formula: F1-Score = 2 \\* ((Precision \\* Recall) / (Precision + Recall))\n",
    "-   A high F1-Score indicates the model is performing well in both precision and recall.\n",
    "\n",
    "-   **Class 0**: \\( 0.78 \\)\n",
    "-   **Class 1**: \\( 0.81 \\)\n",
    "-   **Class 2**: \\( 0.83 \\)\n",
    "\n",
    "#### **Support**\n",
    "\n",
    "-   Support refers to the number of samples in each class in the test dataset.\n",
    "-   **Class 0**: \\( 4663 \\)\n",
    "-   **Class 1**: \\( 9323 \\)\n",
    "-   **Class 2**: \\( 4662 \\)\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Overall Metrics**\n",
    "\n",
    "#### **Accuracy**\n",
    "\n",
    "-   Accuracy is the ratio of correctly predicted samples to the total number of samples.\n",
    "-   **Result**: \\( 0.805 \\) (The model correctly predicted 80.5% of the samples.)\n",
    "\n",
    "#### **Macro Average**\n",
    "\n",
    "-   The unweighted mean of precision, recall, and F1-Score across all classes.\n",
    "-   Treats all classes equally, regardless of their support.\n",
    "\n",
    "-   **Macro Precision**: \\( 0.81 \\)\n",
    "-   **Macro Recall**: \\( 0.80 \\)\n",
    "-   **Macro F1-Score**: \\( 0.80 \\)\n",
    "\n",
    "#### **Weighted Average**\n",
    "\n",
    "-   The weighted mean of precision, recall, and F1-Score across all classes.\n",
    "-   Weights each class’s metric by its support, giving more importance to classes with more samples.\n",
    "\n",
    "-   **Weighted Precision**: \\( 0.81 \\)\n",
    "-   **Weighted Recall**: \\( 0.81 \\)\n",
    "-   **Weighted F1-Score**: \\( 0.81 \\)\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Feature Importance**\n",
    "\n",
    "The following table shows the top 10 most important features identified by the Random Forest model for predicting `googleplus_class`:\n",
    "\n",
    "| Rank | Feature | Importance |\n",
    "|---|---|---|\n",
    "| 1 | PublishHour | 0.2598 |\n",
    "| 2 | Sentiment\\_mean | 0.2457 |\n",
    "| 3 | Source\\_freq | 0.1786 |\n",
    "| 4 | Topic\\_obama | 0.1348 |\n",
    "| 5 | Topic\\_microsoft | 0.0659 |\n",
    "| 6 | Topic\\_palestine | 0.0587 |\n",
    "| 7 | TimeOfDay\\_Night | 0.0171 |\n",
    "| 8 | TimeOfDay\\_Morning | 0.0107 |\n",
    "| 9 | TimeOfDay\\_Evening | 0.0082 |\n",
    "| 10 | PublishDay\\_Tuesday | 0.0038 |\n",
    "\n",
    "These values indicate the relative importance of each feature in the model's decision-making process. `PublishHour`, `Sentiment_mean`, and `Source_freq` are the most influential features.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "\n",
    "1.  **Reasonable Performance**: The model achieves an overall accuracy of approximately 80.5%.\n",
    "2.  **Feature Importance**: `PublishHour`, `Sentiment_mean`, and `Source_freq` are the most important features for predicting GooglePlus class. This suggests that the time of day the article was published, the overall sentiment, and the frequency of the source are strong indicators of GooglePlus engagement.\n",
    "3. The model performance is slightly lower than the facebook model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model for LinkedIn_Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing for linkedin_class...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      4662\n",
      "           1       0.83      0.85      0.84      9326\n",
      "           2       0.77      0.75      0.76      4660\n",
      "\n",
      "    accuracy                           0.84     18648\n",
      "   macro avg       0.84      0.84      0.84     18648\n",
      "weighted avg       0.84      0.84      0.84     18648\n",
      "\n",
      "Accuracy Score: 0.8384813384813384\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "1. Topic_obama (0.3493)\n",
      "2. Sentiment_mean (0.2104)\n",
      "3. PublishHour (0.1581)\n",
      "4. Source_freq (0.1376)\n",
      "5. TimeOfDay_Morning (0.0747)\n",
      "6. Topic_microsoft (0.0255)\n",
      "7. Topic_palestine (0.0102)\n",
      "8. TimeOfDay_Night (0.0097)\n",
      "9. TimeOfDay_Evening (0.0058)\n",
      "10. PublishDay_Thursday (0.0035)\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess data\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesses the data for modeling.\n",
    "    - Encodes categorical variables.\n",
    "    - Scales numerical features.\n",
    "    - Encodes the 'Source' column using frequency encoding.\n",
    "    \"\"\"\n",
    "    # Work on a copy of the DataFrame to avoid altering the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Frequency encoding for 'Source'\n",
    "    source_freq = df_copy['Source'].value_counts(normalize=True)  # Normalize for proportion-based encoding\n",
    "    df_copy['Source_freq'] = df_copy['Source'].map(source_freq)\n",
    "    df_copy.drop(columns=['Source'], inplace=True)  # Drop original Source column\n",
    "\n",
    "    # One-hot encode other categorical features\n",
    "    categorical_cols = ['Topic', 'PublishDay', 'TimeOfDay']\n",
    "    df_encoded = pd.get_dummies(df_copy, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Scaling numerical columns\n",
    "    numerical_cols = ['Sentiment_mean']\n",
    "    scaler = StandardScaler()\n",
    "    df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "# Function to split data\n",
    "def split_data(df, target_col):\n",
    "    \"\"\"\n",
    "    Splits the data into train and test sets.\n",
    "    - df: DataFrame\n",
    "    - target_col: Target column name\n",
    "    \"\"\"\n",
    "    X = df.drop(columns=[target_col, 'IDLink', 'Title', 'Headline', \"PublishDate\", \"googleplus_class\", \"facebook_class\",\"SentimentHeadline\",\"SentimentTitle\"])\n",
    "    y = df[target_col]\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest model.\n",
    "    - Returns the trained model.\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to evaluate a model and print feature importance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test set and prints feature importance.\n",
    "    - Prints classification report, accuracy, and top features.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Print feature importances (if the model has a feature_importances_ attribute)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        feature_names = list(X_test.columns)\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        # Print top 10 most important features\n",
    "        print(\"\\nTop 10 Most Important Features:\")\n",
    "        for i, idx in enumerate(sorted_indices[:10]):\n",
    "            print(f\"{i+1}. {feature_names[idx]} ({importances[idx]:.4f})\")\n",
    "\n",
    "\n",
    "# Main function to process the pipeline\n",
    "def main_pipeline(df, target_col):\n",
    "    \"\"\"\n",
    "    End-to-end pipeline for preprocessing, training, and evaluation.\n",
    "    - df: DataFrame\n",
    "    - target_col: Target column for prediction\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing for {target_col}...\")\n",
    "    df_preprocessed = preprocess_data(df)\n",
    "    X_train, X_test, y_train, y_test = split_data(df_preprocessed, target_col)\n",
    "    model = train_model(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    return model\n",
    "linkedin_model = main_pipeline(df, 'linkedin_class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The outputs provide an evaluation of the classifier's performance on the `linkedin_class` target variable, with the following metrics:\n",
    "\n",
    "---\n",
    "\n",
    "### LinkedIn Classification Model Evaluation\n",
    "\n",
    "The following metrics summarize the performance of the LinkedIn classification model on the test dataset:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Classification Report**\n",
    "\n",
    "This report includes metrics for each class (0, 1, and 2) in the target variable:\n",
    "\n",
    "#### **Precision**\n",
    "\n",
    "-   Precision measures how many of the predicted positive instances for a class are actually correct.\n",
    "-   Formula: Precision = True Positives / (True Positives + False Positives)\n",
    "-   High precision indicates that the model has low false positive rates.\n",
    "\n",
    "-   **Class 0**: \\( 0.92 \\) (92% of samples predicted as class 0 are actually class 0.)\n",
    "-   **Class 1**: \\( 0.83 \\) (83% of samples predicted as class 1 are actually class 1.)\n",
    "-   **Class 2**: \\( 0.77 \\) (77% of samples predicted as class 2 are actually class 2.)\n",
    "\n",
    "#### **Recall**\n",
    "\n",
    "-   Recall measures how many of the actual positive instances for a class the model correctly identified.\n",
    "-   Formula: Recall = True Positives / (False Negatives + True Positives)\n",
    "-   High recall indicates that the model has low false negative rates.\n",
    "\n",
    "-   **Class 0**: \\( 0.91 \\) (91% of actual class 0 samples were correctly identified.)\n",
    "-   **Class 1**: \\( 0.85 \\) (85% of actual class 1 samples were correctly identified.)\n",
    "-   **Class 2**: \\( 0.75 \\) (75% of actual class 2 samples were correctly identified.)\n",
    "\n",
    "#### **F1-Score**\n",
    "\n",
    "-   F1-Score is the harmonic mean of precision and recall, providing a single score that balances both metrics.\n",
    "-   Formula: F1-Score = 2 \\* ((Precision \\* Recall) / (Precision + Recall))\n",
    "-   A high F1-Score indicates the model is performing well in both precision and recall.\n",
    "\n",
    "-   **Class 0**: \\( 0.91 \\)\n",
    "-   **Class 1**: \\( 0.84 \\)\n",
    "-   **Class 2**: \\( 0.76 \\)\n",
    "\n",
    "#### **Support**\n",
    "\n",
    "-   Support refers to the number of samples in each class in the test dataset.\n",
    "-   **Class 0**: \\( 4662 \\)\n",
    "-   **Class 1**: \\( 9326 \\)\n",
    "-   **Class 2**: \\( 4660 \\)\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Overall Metrics**\n",
    "\n",
    "#### **Accuracy**\n",
    "\n",
    "-   Accuracy is the ratio of correctly predicted samples to the total number of samples.\n",
    "-   **Result**: \\( 0.838 \\) (The model correctly predicted 83.8% of the samples.)\n",
    "\n",
    "#### **Macro Average**\n",
    "\n",
    "-   The unweighted mean of precision, recall, and F1-Score across all classes.\n",
    "-   Treats all classes equally, regardless of their support.\n",
    "\n",
    "-   **Macro Precision**: \\( 0.84 \\)\n",
    "-   **Macro Recall**: \\( 0.84 \\)\n",
    "-   **Macro F1-Score**: \\( 0.84 \\)\n",
    "\n",
    "#### **Weighted Average**\n",
    "\n",
    "-   The weighted mean of precision, recall, and F1-Score across all classes.\n",
    "-   Weights each class’s metric by its support, giving more importance to classes with more samples.\n",
    "\n",
    "-   **Weighted Precision**: \\( 0.84 \\)\n",
    "-   **Weighted Recall**: \\( 0.84 \\)\n",
    "-   **Weighted F1-Score**: \\( 0.84 \\)\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Feature Importance**\n",
    "\n",
    "The following table shows the top 10 most important features identified by the Random Forest model for predicting `linkedin_class`:\n",
    "\n",
    "| Rank | Feature | Importance |\n",
    "|---|---|---|\n",
    "| 1 | Topic\\_obama | 0.3493 |\n",
    "| 2 | Sentiment\\_mean | 0.2104 |\n",
    "| 3 | PublishHour | 0.1581 |\n",
    "| 4 | Source\\_freq | 0.1376 |\n",
    "| 5 | TimeOfDay\\_Morning | 0.0747 |\n",
    "| 6 | Topic\\_microsoft | 0.0255 |\n",
    "| 7 | Topic\\_palestine | 0.0102 |\n",
    "| 8 | TimeOfDay\\_Night | 0.0097 |\n",
    "| 9 | TimeOfDay\\_Evening | 0.0058 |\n",
    "| 10 | PublishDay\\_Thursday | 0.0035 |\n",
    "\n",
    "These values indicate the relative importance of each feature in the model's decision-making process. `Topic_obama`, `Sentiment_mean`, and `PublishHour` are the most influential features for predicting LinkedIn engagement.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "\n",
    "1.  **Reasonable Performance**: The model achieves an overall accuracy of approximately 83.8%.\n",
    "2.  **Feature Importance**: `Topic_obama` is by far the most important feature for predicting LinkedIn class, followed by `Sentiment_mean` and `PublishHour`. This suggests that the topic of the article, especially if it's about Obama, the overall sentiment, and the time of day are strong indicators of LinkedIn engagement.\n",
    "3. The model performs best on class 0 (LOW Popularity Articles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Popularity Continous Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned Data after passing through ETL File:\n",
    "data=pd.read_csv(\"Cleaned_News.csv\")\n",
    "\n",
    "# Converting PublishDate into datetime[ns]\n",
    "data['PublishDate'] = pd.to_datetime(data['PublishDate'], errors='coerce')\n",
    "\n",
    "# Creating new Columns same as above :\n",
    "def create_derived_features(df):\n",
    "    \"\"\"Creates derived features from existing columns.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame containing news data with 'SentimentTitle',\n",
    "            'SentimentHeadline', and 'PublishDate' columns.\n",
    "\n",
    "    Returns:\n",
    "        A new Pandas DataFrame with the derived features, or the original\n",
    "        DataFrame if the required columns are missing. Returns None if input is not a dataframe.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Input is not a Pandas DataFrame\")\n",
    "        return None\n",
    "    df_derived = df.copy()\n",
    "\n",
    "    required_cols = ['SentimentTitle', 'SentimentHeadline', 'PublishDate']\n",
    "    if not all(col in df_derived.columns for col in required_cols):\n",
    "        print(f\"Missing required columns: {set(required_cols) - set(df_derived.columns)}\")\n",
    "        return df_derived  # Return original if columns are missing\n",
    "\n",
    "    # 1. Sentiment Mean\n",
    "    df_derived['Sentiment_mean'] = df_derived[['SentimentTitle', 'SentimentHeadline']].mean(axis=1)\n",
    "\n",
    "    # 2. Publish Day\n",
    "    df_derived['PublishDay'] = df_derived['PublishDate'].dt.day_name()\n",
    "\n",
    "    # 3. Publish Hour\n",
    "    df_derived['PublishHour'] = df_derived['PublishDate'].dt.hour\n",
    "\n",
    "    # 4. Time of Day\n",
    "    def categorize_time(hour):\n",
    "        if 6 <= hour < 12:\n",
    "            return 'Morning'\n",
    "        elif 12 <= hour < 17:\n",
    "            return 'Afternoon'\n",
    "        elif 17 <= hour < 21:\n",
    "            return 'Evening'\n",
    "        else:\n",
    "            return 'Night'\n",
    "\n",
    "    df_derived['TimeOfDay'] = df_derived['PublishHour'].apply(categorize_time)\n",
    "\n",
    "    return df_derived\n",
    "\n",
    "data = create_derived_features(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IDLink', 'Title', 'Headline', 'Source', 'Topic', 'PublishDate',\n",
       "       'SentimentTitle', 'SentimentHeadline', 'Facebook', 'GooglePlus',\n",
       "       'LinkedIn', 'Sentiment_mean', 'PublishDay', 'PublishHour', 'TimeOfDay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDLink                        int64\n",
       "Title                        object\n",
       "Headline                     object\n",
       "Source                       object\n",
       "Topic                        object\n",
       "PublishDate          datetime64[ns]\n",
       "SentimentTitle              float64\n",
       "SentimentHeadline           float64\n",
       "Facebook                    float64\n",
       "GooglePlus                  float64\n",
       "LinkedIn                    float64\n",
       "Sentiment_mean              float64\n",
       "PublishDay                   object\n",
       "PublishHour                   int32\n",
       "TimeOfDay                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDLink</th>\n",
       "      <th>Title</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Topic</th>\n",
       "      <th>PublishDate</th>\n",
       "      <th>SentimentTitle</th>\n",
       "      <th>SentimentHeadline</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Sentiment_mean</th>\n",
       "      <th>PublishDay</th>\n",
       "      <th>PublishHour</th>\n",
       "      <th>TimeOfDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99248</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
       "      <td>USA TODAY</td>\n",
       "      <td>obama</td>\n",
       "      <td>2002-04-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053300</td>\n",
       "      <td>2547.659722</td>\n",
       "      <td>1538.570833</td>\n",
       "      <td>499.025000</td>\n",
       "      <td>-0.026650</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10423</td>\n",
       "      <td>A Look at the Health of the Chinese Economy</td>\n",
       "      <td>Tim Haywood investment director businessunit h...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>economy</td>\n",
       "      <td>2008-09-20</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>-0.156386</td>\n",
       "      <td>1380.145833</td>\n",
       "      <td>1957.444444</td>\n",
       "      <td>753.729167</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDLink                                             Title  \\\n",
       "0   99248  Obama Lays Wreath at Arlington National Cemetery   \n",
       "1   10423       A Look at the Health of the Chinese Economy   \n",
       "\n",
       "                                            Headline     Source    Topic  \\\n",
       "0  Obama Lays Wreath at Arlington National Cemete...  USA TODAY    obama   \n",
       "1  Tim Haywood investment director businessunit h...  Bloomberg  economy   \n",
       "\n",
       "  PublishDate  SentimentTitle  SentimentHeadline     Facebook   GooglePlus  \\\n",
       "0  2002-04-02        0.000000          -0.053300  2547.659722  1538.570833   \n",
       "1  2008-09-20        0.208333          -0.156386  1380.145833  1957.444444   \n",
       "\n",
       "     LinkedIn  Sentiment_mean PublishDay  PublishHour TimeOfDay  \n",
       "0  499.025000       -0.026650    Tuesday            0     Night  \n",
       "1  753.729167        0.025974   Saturday            0     Night  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolutely, here's a breakdown of what each feature in the function does:\n",
    "\n",
    "**1. Target Variables (lines 5-7):**\n",
    "  - `df['Facebook'] = np.log1p(df['Facebook'] + 1)`: Applies a logarithmic transformation (log1p) to the \"Facebook\" engagement column. This helps normalize the skewed distribution of social media engagement data.\n",
    "\n",
    "**2. Feature Engineering - Top Sources (lines 9-22):**\n",
    "  - This section identifies the top 10 sources for each topic based on their counts.\n",
    "  - New features are created indicating if a post comes from one of those top sources for a specific topic (e.g., \"source_is_Politics_NewYorkTimes\").\n",
    "\n",
    "**3. Feature Engineering - One-Hot Encoding (lines 24-32):**\n",
    "  - Categorical features like \"Topic\", \"PublishDay\", and \"TimeOfDay\" are converted into one-hot encoded features. This allows the model to learn the relationship between these categories and the target variable.\n",
    "\n",
    "**4. Feature Engineering - Sentiment Scaling (lines 34-35):**\n",
    "  - The \"Sentiment_mean\" feature is standardized using a StandardScaler. This ensures all features are on a similar scale for better model performance.\n",
    "\n",
    "**5. Feature Engineering - Weekend Flag (lines 37-38):**\n",
    "  - A new feature \"is_weekend\" is created to indicate if the post was published on a Saturday or Sunday.\n",
    "\n",
    "**6. Text Preprocessing (lines 39-52):**\n",
    "  - This function defines how text features (\"Headline\" and \"Title\") are cleaned:\n",
    "      - Converts text to lowercase.\n",
    "      - Removes non-alphanumeric characters.\n",
    "      - Removes stop words (common words like \"the\", \"a\", \"an\").\n",
    "      - Returns a space-separated string of remaining words.\n",
    "\n",
    "**7. Feature Engineering - Text Vectorization (lines 54-70):**\n",
    "  - Two CountVectorizers are used:\n",
    "      - One for 5-grams in the \"CleanedHeadline\" (maximum 20 features).\n",
    "      - Another for 3-grams in the \"CleanedTitle\" (maximum 20 features).\n",
    "  - This creates new features representing the frequency of n-gram word patterns in the headlines and titles.\n",
    "\n",
    "**8. Feature Selection (lines 72-77):**\n",
    "  - Selects all features containing \"is_\", \"PublishDay_\", \"TimeOfDay_\", \"Sentiment_mean_scaled\", \"source_is_\", all features from the CountVectorizers, and \"is_weekend\".\n",
    "  - Removes any features with constant values across all samples.\n",
    "\n",
    "**9. Splitting Data (lines 79-80):**\n",
    "  - Returns two DataFrames:\n",
    "      - `X`: Contains the preprocessed features used for model training.\n",
    "      - `df[['Facebook', 'GooglePlus', 'LinkedIn']]`: Contains the original target variables (engagement) for each platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocesses the data for social media engagement prediction.\"\"\"\n",
    "\n",
    "    df['Facebook'] = np.log1p(df['Facebook'] + 1)\n",
    "    df['GooglePlus'] = np.log1p(df['GooglePlus'] + 1)\n",
    "    df['LinkedIn'] = np.log1p(df['LinkedIn'] + 1)\n",
    "\n",
    "    source_counts = df.groupby(['Topic', 'Source'])['Source'].count().unstack(fill_value=0)\n",
    "    top_10_sources = {}\n",
    "    for topic in df['Topic'].unique():\n",
    "        top_10_sources[topic] = source_counts.loc[topic].nlargest(10).index.tolist()\n",
    "\n",
    "    for topic, sources in top_10_sources.items():\n",
    "        for source in sources:\n",
    "            source_col = f\"source_is_{topic}_{source.replace(' ', '_')}\"\n",
    "            df[source_col] = (df['Topic'] == topic) & (df['Source'] == source)\n",
    "            \n",
    "    categorical_features = ['Topic', 'PublishDay', 'TimeOfDay']\n",
    "    for feature in categorical_features:\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        encoded = ohe.fit_transform(df[[feature]])\n",
    "        encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out([feature]))\n",
    "        df = pd.concat([df, encoded_df], axis=1)\n",
    "        df.drop(feature, axis=1, inplace=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df['Sentiment_mean_scaled'] = scaler.fit_transform(df[['Sentiment_mean']].values)\n",
    "\n",
    "    df['is_weekend'] = (df['PublishDay_Saturday'] == 1) | (df['PublishDay_Sunday'] == 1)\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"  # Return empty string instead of list for CountVectorizer\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        tokens = [word for word in text.split() if word not in stop_words]\n",
    "        return \" \".join(tokens)  # Return space-separated string\n",
    "\n",
    "    df['CleanedHeadline'] = df['Headline'].apply(preprocess_text)\n",
    "    df['CleanedTitle'] = df['Title'].apply(preprocess_text)\n",
    "\n",
    "    headline_vectorizer = CountVectorizer(max_features=20, ngram_range=(5, 5))\n",
    "    headline_patterns = headline_vectorizer.fit_transform(df['CleanedHeadline']).toarray()\n",
    "    df = pd.concat([df, pd.DataFrame(headline_patterns, columns=headline_vectorizer.get_feature_names_out())], axis=1)\n",
    "\n",
    "    title_vectorizer = CountVectorizer(max_features=20, ngram_range=(3, 3))\n",
    "    title_patterns = title_vectorizer.fit_transform(df['CleanedTitle']).toarray()\n",
    "    df = pd.concat([df, pd.DataFrame(title_patterns, columns=title_vectorizer.get_feature_names_out())], axis=1)\n",
    "\n",
    "    feature_cols = list(df.filter(like='is_')) + list(df.filter(like='PublishDay_')) + list(df.filter(like='TimeOfDay_')) + ['Sentiment_mean_scaled'] + list(df.filter(like='source_is_')) + list(headline_vectorizer.get_feature_names_out()) + list(title_vectorizer.get_feature_names_out()) + ['is_weekend']\n",
    "    X = df[feature_cols]\n",
    "    X = X.loc[:, (X != X.iloc[0]).any()]\n",
    "\n",
    "    return X, df[['Facebook', 'GooglePlus', 'LinkedIn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BaseLine Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Facebook:\n",
      "  MSE: 263891.36\n",
      "  RMSE: 513.70\n",
      "  R-squared: 0.27\n",
      "------------------------------\n",
      "Results for GooglePlus:\n",
      "  MSE: 192194.94\n",
      "  RMSE: 438.40\n",
      "  R-squared: 0.24\n",
      "------------------------------\n",
      "Results for LinkedIn:\n",
      "  MSE: 34803.57\n",
      "  RMSE: 186.56\n",
      "  R-squared: 0.35\n",
      "------------------------------\n",
      "Summary of all results:\n",
      "Facebook: R-squared = 0.27\n",
      "GooglePlus: R-squared = 0.24\n",
      "LinkedIn: R-squared = 0.35\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def train_and_evaluate(X, y, target_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_test_original = np.expm1(y_test)\n",
    "    y_pred_original = np.expm1(y_pred)\n",
    "\n",
    "    mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_original, y_pred_original)\n",
    "\n",
    "    print(f\"Results for {target_name}:\")\n",
    "    print(f\"  MSE: {mse:.2f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  R-squared: {r2:.2f}\")\n",
    "    print(\"-\" * 30)\n",
    "    return {'MSE': mse, 'RMSE': rmse, 'R-squared': r2}\n",
    "\n",
    "# Main execution\n",
    "news = data.copy() #data is your dataframe\n",
    "X, y = preprocess_data(news)\n",
    "\n",
    "results = {}\n",
    "for target in y.columns:  # Iterate through all target columns\n",
    "    results[target] = train_and_evaluate(X, y[target], target)\n",
    "\n",
    "# Print summary of all results (optional)\n",
    "print(\"Summary of all results:\")\n",
    "for target, metrics in results.items():\n",
    "    print(f\"{target}: R-squared = {metrics['R-squared']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation Results:**\n",
    "\n",
    "The following metrics evaluate the performance of the linear regression models for predicting social media engagement on Facebook, GooglePlus, and LinkedIn.\n",
    "\n",
    "*   **Mean Squared Error (MSE):** Average of squared prediction errors. MSE = (1/n) * Σ(yᵢ - ŷᵢ)²\n",
    "*   **Root Mean Squared Error (RMSE):** Square root of MSE, in the same units as the target. RMSE = sqrt(MSE)\n",
    "*   **R-squared (R²):** Proportion of variance in the target explained by the model. R² = 1 - (SSres / SStot)\n",
    "\n",
    "**Facebook:**\n",
    "\n",
    "*   **MSE: 263891.36:** The average squared prediction error is 263891.36.\n",
    "*   **RMSE: 513.70:** On average, predictions deviate from actual Facebook share counts by approximately 513.70.\n",
    "*   **R-squared: 0.27:** The model explains 27% of the variance in Facebook shares, indicating a weak fit.\n",
    "\n",
    "**GooglePlus:**\n",
    "\n",
    "*   **MSE: 192194.94:** The average squared prediction error is 192194.94.\n",
    "*   **RMSE: 438.40:** On average, predictions deviate from actual GooglePlus share counts by approximately 438.40.\n",
    "*   **R-squared: 0.24:** The model explains 24% of the variance in GooglePlus shares, also indicating a weak fit.\n",
    "\n",
    "**LinkedIn:**\n",
    "\n",
    "*   **MSE: 34803.57:** The average squared prediction error is 34803.57.\n",
    "*   **RMSE: 186.56:** On average, predictions deviate from actual LinkedIn share counts by approximately 186.56.\n",
    "*   **R-squared: 0.35:** The model explains 35% of the variance in LinkedIn shares, representing the relatively best fit among the three, but still not a strong fit.\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "The low R-squared values across all three platforms suggest that a linear model, with the current set of features, does not adequately capture the complex dynamics of social media engagement. Other models or additional features might be more appropriate. Therefore we will use this simple model as the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Facebook (Random Forest):\n",
      "  MSE: 282531.20\n",
      "  RMSE: 531.54\n",
      "  R-squared: 0.22\n",
      "------------------------------\n",
      "Results for GooglePlus (Random Forest):\n",
      "  MSE: 218617.72\n",
      "  RMSE: 467.57\n",
      "  R-squared: 0.14\n",
      "------------------------------\n",
      "Results for LinkedIn (Random Forest):\n",
      "  MSE: 42194.76\n",
      "  RMSE: 205.41\n",
      "  R-squared: 0.21\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# ... (preprocess_data function remains the same)\n",
    "\n",
    "def train_and_evaluate_rf(X, y, target_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y[target_name], test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    best_model = None\n",
    "    best_rmse = float('inf')\n",
    "    for n_estimators in range(10, 101, 10):\n",
    "        rf_model = RandomForestRegressor(n_estimators=n_estimators, random_state=42, n_jobs=-1)\n",
    "        rf_model.fit(X_train_scaled, y_train)\n",
    "        y_pred = rf_model.predict(X_test_scaled)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        if rmse < best_rmse:\n",
    "            best_model = rf_model\n",
    "            best_rmse = rmse\n",
    "\n",
    "    try:\n",
    "        y_pred = best_model.predict(X_test_scaled)\n",
    "        # Correct inverse transform: Apply expm1 to predictions and *test* values\n",
    "        y_pred_original = np.expm1(y_pred)\n",
    "        y_test_original = np.expm1(y_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test_original, y_pred_original)\n",
    "        return {'MSE': mse, 'RMSE': rmse, 'R-squared': r2}\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction or evaluation for {target_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "news = data.copy()\n",
    "X, y = preprocess_data(news)\n",
    "targets = y.columns\n",
    "results = {}\n",
    "\n",
    "for target in targets:\n",
    "    metrics = train_and_evaluate_rf(X, y, target)\n",
    "    if metrics is not None:\n",
    "        results[target] = metrics\n",
    "        print(f\"Results for {target} (Random Forest):\")\n",
    "        print(f\"  MSE: {metrics['MSE']:.2f}\")\n",
    "        print(f\"  RMSE: {metrics['RMSE']:.2f}\")\n",
    "        print(f\"  R-squared: {metrics['R-squared']:.2f}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation Results (Random Forest):**\n",
    "\n",
    "The following metrics evaluate the performance of the Random Forest models for predicting social media engagement on Facebook, GooglePlus, and LinkedIn.\n",
    "\n",
    "*   **Mean Squared Error (MSE):** Average of squared prediction errors. MSE = (1/n) * Σ(yᵢ - ŷᵢ)²\n",
    "*   **Root Mean Squared Error (RMSE):** Square root of MSE, in the same units as the target. RMSE = sqrt(MSE)\n",
    "*   **R-squared (R²):** Proportion of variance in the target explained by the model. R² = 1 - (SSres / SStot)\n",
    "\n",
    "**Facebook:**\n",
    "\n",
    "*   **MSE: 282531.20:** The average squared prediction error is 282531.20. This indicates a relatively high average squared difference between the predicted and actual Facebook engagement counts.\n",
    "*   **RMSE: 531.54:** On average, predictions deviate from actual Facebook engagement counts by approximately 531.54. This gives a more interpretable measure of the prediction error in the original units of the target variable.\n",
    "*   **R-squared: 0.22:** The model explains 22% of the variance in Facebook engagement, indicating a weak fit. This suggests that the Random Forest model, with the current features, does not capture a large portion of the factors influencing Facebook engagement.\n",
    "\n",
    "**GooglePlus:**\n",
    "\n",
    "*   **MSE: 218617.72:** The average squared prediction error is 218617.72. Similar to Facebook, this value suggests a considerable average squared difference between predictions and actual GooglePlus engagement.\n",
    "*   **RMSE: 467.57:** On average, predictions deviate from actual GooglePlus engagement counts by approximately 467.57.\n",
    "*   **R-squared: 0.14:** The model explains only 14% of the variance in GooglePlus engagement, indicating a very weak fit. This model performs the worst among the three platforms in terms of explained variance.\n",
    "\n",
    "**LinkedIn:**\n",
    "\n",
    "*   **MSE: 42194.76:** The average squared prediction error is 42194.76. This is the lowest MSE among the three platforms, suggesting better prediction accuracy for LinkedIn compared to Facebook and GooglePlus.\n",
    "*   **RMSE: 205.41:** On average, predictions deviate from actual LinkedIn engagement counts by approximately 205.41.\n",
    "*   **R-squared: 0.21:** The model explains 21% of the variance in LinkedIn engagement, indicating a weak fit, although slightly better than GooglePlus but similar to Facebook.\n",
    "\n",
    "**Comparison with Linear Regression:**\n",
    "\n",
    "Here's a comparison of the Random Forest results with the previous Linear Regression results you provided:\n",
    "\n",
    "| Metric      | Platform   | Random Forest | Linear Regression |\n",
    "| ----------- | ---------- | ------------- | ----------------- |\n",
    "| MSE         | Facebook   | 282531.20     | 263891.36         |\n",
    "| RMSE        | Facebook   | 531.54        | 513.70            |\n",
    "| R-squared   | Facebook   | 0.22          | 0.27              |\n",
    "| MSE         | GooglePlus | 218617.72     | 192194.94         |\n",
    "| RMSE        | GooglePlus | 467.57        | 438.40            |\n",
    "| R-squared   | GooglePlus | 0.14          | 0.24              |\n",
    "| MSE         | LinkedIn   | 42194.76      | 34803.57          |\n",
    "| RMSE        | LinkedIn   | 205.41        | 186.56            |\n",
    "| R-squared   | LinkedIn   | 0.21          | 0.35              |\n",
    "\n",
    "**Summary and Comparison:**\n",
    "\n",
    "The Random Forest models, in this case, perform *slightly worse* than the Linear Regression models across all three platforms based on R-squared. The MSE and RMSE are also generally higher for the Random Forest, indicating larger prediction errors. While Random Forests are generally powerful and can capture non-linear relationships, in this specific scenario, with the current feature set and hyperparameters, they do not outperform the simpler linear models. The low R-squared values for both models across all platforms still point to the need for potentially more relevant features, feature engineering, or exploring other model types to better predict social media engagement. It's important to note that Random Forests have many hyperparameters that can be tuned to potentially improve performance; further experimentation and optimization might be necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================] - 1s 1ms/step\n",
      "583/583 [==============================] - 1s 1ms/step\n",
      "583/583 [==============================] - 1s 1ms/step\n",
      "Results for Facebook (Neural Network):\n",
      "  MSE: 221521.47\n",
      "  RMSE: 470.66\n",
      "  R-squared: 0.39\n",
      "------------------------------\n",
      "Results for GooglePlus (Neural Network):\n",
      "  MSE: 185423.64\n",
      "  RMSE: 430.61\n",
      "  R-squared: 0.27\n",
      "------------------------------\n",
      "Results for LinkedIn (Neural Network):\n",
      "  MSE: 33161.18\n",
      "  RMSE: 182.10\n",
      "  R-squared: 0.38\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "# Download stopwords (one-time download)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesses the input data for the neural network model.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the preprocessed features (X) and target variables (y).\n",
    "    \"\"\"\n",
    "\n",
    "    # One-Hot Encoding for Topic, Day of Week, Time of Day\n",
    "    ohe_topic = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    topic_encoded = ohe_topic.fit_transform(df[['Topic']])\n",
    "    topic_df = pd.DataFrame(topic_encoded, columns=ohe_topic.get_feature_names_out(['Topic']))\n",
    "    df = pd.concat([df, topic_df], axis=1)\n",
    "\n",
    "    ohe_day = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    day_encoded = ohe_day.fit_transform(df[['PublishDay']])\n",
    "    day_df = pd.DataFrame(day_encoded, columns=ohe_day.get_feature_names_out(['PublishDay']))\n",
    "    df = pd.concat([df, day_df], axis=1)\n",
    "\n",
    "    ohe_time = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    time_encoded = ohe_time.fit_transform(df[['TimeOfDay']])\n",
    "    time_df = pd.DataFrame(time_encoded, columns=ohe_time.get_feature_names_out(['TimeOfDay']))\n",
    "    df = pd.concat([df, time_df], axis=1)\n",
    "\n",
    "    # Scaling numerical features\n",
    "    scaler = StandardScaler()\n",
    "    df['Sentiment_mean_scaled'] = scaler.fit_transform(df[['Sentiment_mean']].values)\n",
    "\n",
    "    # Feature Engineering: Source (Frequency Encoding)\n",
    "    source_counts = df.groupby(['Topic', 'Source'])['Source'].count().unstack(fill_value=0)\n",
    "    top_10_sources = {}\n",
    "    for topic in df['Topic'].unique():\n",
    "        top_10_sources[topic] = source_counts.loc[topic].nlargest(10).index.tolist()\n",
    "\n",
    "    for topic, sources in top_10_sources.items():\n",
    "        for source in sources:\n",
    "            source_col = f\"source_is_{topic}_{source.replace(' ', '_')}\"  # More robust column names\n",
    "            df[source_col] = (df['Topic'] == topic) & (df['Source'] == source)\n",
    "\n",
    "    df[\"is_weekend\"] = ((df['PublishDay_Saturday'] == 1) | (df['PublishDay_Sunday'] == 1))\n",
    "\n",
    "    # Text Preprocessing (for Headline and Title)\n",
    "    def preprocess_text(text):\n",
    "        if isinstance(text, float) and math.isnan(text):\n",
    "            return []\n",
    "        text = str(text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        tokens = [word for word in text.split() if word not in stop_words]\n",
    "        return tokens\n",
    "\n",
    "    df['CleanedHeadline'] = df['Headline'].apply(preprocess_text)\n",
    "    df['CleanedTitle'] = df['Title'].apply(preprocess_text)\n",
    "\n",
    "    # Feature Engineering: Common Words in Headline and Title (using CountVectorizer)\n",
    "    headline_vectorizer = CountVectorizer(max_features=20, ngram_range=(5, 5))\n",
    "    headline_patterns = headline_vectorizer.fit_transform(df['CleanedHeadline'].apply(lambda x: \" \".join(x))).toarray()\n",
    "    df = pd.concat([df, pd.DataFrame(headline_patterns, columns=headline_vectorizer.get_feature_names_out())], axis=1)\n",
    "\n",
    "    title_vectorizer = CountVectorizer(max_features=20, ngram_range=(3, 3))\n",
    "    title_patterns = title_vectorizer.fit_transform(df['CleanedTitle'].apply(lambda x: \" \".join(x))).toarray()\n",
    "    df = pd.concat([df, pd.DataFrame(title_patterns, columns=title_vectorizer.get_feature_names_out())], axis=1)\n",
    "\n",
    "    # Feature Selection\n",
    "    feature_cols = list(df.filter(like='is_')) + list(df.filter(like='PublishDay_')) + list(df.filter(like='TimeOfDay_')) + ['Sentiment_mean_scaled'] + list(df.filter(like='source_is_')) + list(df.filter(regex=r'\\b\\w+(?:\\s+\\w+){4}\\b')) + list(df.filter(regex=r'\\b\\w+(?:\\s+\\w+){2}\\b')) + [\"is_weekend\"]\n",
    "\n",
    "    X = df[feature_cols]\n",
    "    X = X.loc[:, (X != X.iloc[0]).any()]\n",
    "\n",
    "    return X\n",
    "\n",
    "def build_and_evaluate_model(X, y, target):\n",
    "    \"\"\"\n",
    "    Builds, trains, and evaluates a neural network model for the given target variable.\n",
    "\n",
    "    Args:\n",
    "        X (pandas.DataFrame): The preprocessed features.\n",
    "        y (pandas.Series): The target variable.\n",
    "        target (str): The name of the target variable.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing evaluation metrics (MSE, RMSE, R-squared).\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Build the Neural Network Model\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=[X_train_scaled.shape[1]]),  # Input layer + hidden layer\n",
    "        Dropout(0.3),  # Dropout for regularization\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1)  # Output layer (1 neuron for regression)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\n",
    "\n",
    "    # Train the Model with Early Stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', patience=10, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=100,  # Adjust as needed\n",
    "        batch_size=32,  # Adjust as needed\n",
    "        validation_split=0.2,  # Validation split\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred = y_pred.flatten()\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results = {'MSE': mse, 'RMSE': rmse, 'R-squared': r2}\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- Main execution ---\n",
    "df = data.copy()\n",
    "targets = ['Facebook', 'GooglePlus', 'LinkedIn']\n",
    "results = {}\n",
    "\n",
    "# Preprocess the data\n",
    "X = preprocess_data(df.copy())\n",
    "\n",
    "for target in targets:\n",
    "    y = df[target]\n",
    "    results[target] = build_and_evaluate_model(X.copy(), y, target)\n",
    "\n",
    "# Print results\n",
    "for target, metrics in results.items():\n",
    "    print(f\"Results for {target} (Neural Network):\")\n",
    "    print(f\"  MSE: {metrics['MSE']:.2f}\")\n",
    "    print(f\"  RMSE: {metrics['RMSE']:.2f}\")\n",
    "    print(f\"  R-squared: {metrics['R-squared']:.2f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation Results (Neural Network):**\n",
    "\n",
    "The following metrics evaluate the performance of the Neural Network models for predicting social media engagement on Facebook, GooglePlus, and LinkedIn.\n",
    "\n",
    "*   **Mean Squared Error (MSE):** Average of squared prediction errors. MSE = (1/n) * Σ(yᵢ - ŷᵢ)²\n",
    "*   **Root Mean Squared Error (RMSE):** Square root of MSE, in the same units as the target. RMSE = sqrt(MSE)\n",
    "*   **R-squared (R²):** Proportion of variance in the target explained by the model. R² = 1 - (SSres / SStot)\n",
    "\n",
    "**Facebook:**\n",
    "\n",
    "*   **MSE: 221839.39:** The average squared prediction error is 221839.39. This represents the average squared difference between the predicted and actual Facebook engagement counts.\n",
    "*   **RMSE: 471.00:** On average, the model's predictions deviate from the actual Facebook engagement counts by approximately 471.00 units. This provides a more interpretable measure of error in the original scale of the target variable.\n",
    "*   **R-squared: 0.38:** The model explains 38% of the variance in Facebook engagement. This is a moderate fit, suggesting the neural network captures a more significant portion of the factors influencing Facebook engagement compared to previous models.\n",
    "\n",
    "**GooglePlus:**\n",
    "\n",
    "*   **MSE: 184072.60:** The average squared prediction error is 184072.60 for GooglePlus engagement.\n",
    "*   **RMSE: 429.04:** The model's predictions deviate from the actual GooglePlus engagement counts by approximately 429.04 units on average.\n",
    "*   **R-squared: 0.28:** The model explains 28% of the variance in GooglePlus engagement, indicating a slightly better fit than the previous Random Forest and Linear Regression models for this platform, but still not a strong fit.\n",
    "\n",
    "**LinkedIn:**\n",
    "\n",
    "*   **MSE: 33276.79:** The average squared prediction error for LinkedIn engagement is 33276.79. This is the lowest MSE among the three platforms, suggesting better prediction accuracy for LinkedIn compared to Facebook and GooglePlus.\n",
    "*   **RMSE: 182.42:** On average, the predictions deviate from the actual LinkedIn engagement counts by approximately 182.42 units.\n",
    "*   **R-squared: 0.37:** The model explains 37% of the variance in LinkedIn engagement. This is a moderate fit and the best performance among the three platforms, suggesting that the model is relatively more effective at capturing the factors influencing LinkedIn engagement.\n",
    "\n",
    "**Comparison with Linear Regression and Random Forest:**\n",
    "\n",
    "Here's a comparison of the Neural Network results with the previous Linear Regression and Random Forest results:\n",
    "\n",
    "| Metric      | Platform   | Neural Network | Random Forest | Linear Regression |\n",
    "| ----------- | ---------- | -------------- | ------------- | ----------------- |\n",
    "| MSE         | Facebook   | 221839.39      | 282531.20     | 263891.36         |\n",
    "| RMSE        | Facebook   | 470.00         | 531.54        | 513.70            |\n",
    "| R-squared   | Facebook   | 0.38           | 0.22          | 0.27              |\n",
    "| MSE         | GooglePlus | 184072.60      | 218617.72     | 192194.94         |\n",
    "| RMSE        | GooglePlus | 430.04         | 467.57        | 438.40            |\n",
    "| R-squared   | GooglePlus | 0.28           | 0.14          | 0.24              |\n",
    "| MSE         | LinkedIn   | 33276.79       | 42194.76      | 34803.57          |\n",
    "| RMSE        | LinkedIn   | 182.42         | 205.41        | 186.56            |\n",
    "| R-squared   | LinkedIn   | 0.37           | 0.21          | 0.35              |\n",
    "\n",
    "**Summary and Comparison:**\n",
    "\n",
    "The Neural Network models demonstrate a clear improvement over both Linear Regression and Random Forest models in terms of R-squared for all three platforms. The MSE and RMSE values are also generally lower for the Neural Network, indicating reduced prediction errors. This suggests that the neural network is better at capturing the complex, non-linear relationships within the data compared to the linear models and the Random Forest given the current feature set and network architecture. While the R-squared values are still not exceptionally high, the neural network represents the best performing model among the three evaluated so far, particularly for Facebook where it explains 38% of the variance. Further hyperparameter tuning (number of layers, neurons, dropout rates, optimizer, etc.) and feature engineering could potentially further improve the neural network's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 74591, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score 7.387639\n",
      "Results for Facebook (LightGBM):\n",
      "  MSE: 131908.46\n",
      "  RMSE: 363.19\n",
      "  R-squared: 0.63\n",
      "------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 74591, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score 7.460173\n",
      "Results for GooglePlus (LightGBM):\n",
      "  MSE: 75483.17\n",
      "  RMSE: 274.74\n",
      "  R-squared: 0.70\n",
      "------------------------------\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 665\n",
      "[LightGBM] [Info] Number of data points in the train set: 74591, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score 6.625275\n",
      "Results for LinkedIn (LightGBM):\n",
      "  MSE: 19206.81\n",
      "  RMSE: 138.59\n",
      "  R-squared: 0.64\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocesses text.\"\"\"\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    stop_words = set([\"the\", \"and\", \"is\", \"to\", \"in\", \"it\", \"of\", \"for\", \"on\", \"with\", \"as\", \"this\", \"at\", \"by\"])\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def train_and_evaluate_lightgbm(df, target_name):\n",
    "    \"\"\"Trains and evaluates a LightGBM model, suppressing warnings.\"\"\"\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)  # Suppress LightGBM warnings\n",
    "\n",
    "    df['log_' + target_name] = np.log1p(df[target_name] + 1)\n",
    "\n",
    "    df['Year'] = pd.to_datetime(df['PublishDate']).dt.year\n",
    "    df['Month'] = pd.to_datetime(df['PublishDate']).dt.month\n",
    "    df['Day'] = pd.to_datetime(df['PublishDate']).dt.day\n",
    "    df['Hour'] = pd.to_datetime(df['PublishDate']).dt.hour\n",
    "\n",
    "    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)\n",
    "    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "    df['Day_sin'] = np.sin(2 * np.pi * df['Day'] / 31)\n",
    "    df['Day_cos'] = np.cos(2 * np.pi * df['Day'] / 31)\n",
    "\n",
    "    source_topic_counts = df.groupby(['Topic', 'Source']).size().reset_index(name='SourceCount')\n",
    "    total_topic_counts = df.groupby('Topic').size().reset_index(name='TotalCount')\n",
    "\n",
    "    df = df.merge(source_topic_counts, on=['Topic', 'Source'], how='left')\n",
    "    df = df.merge(total_topic_counts, on='Topic', how='left')\n",
    "    df['SourceFreq'] = df['SourceCount'] / df['TotalCount']\n",
    "    df.drop(['SourceCount', 'TotalCount'], axis=1, inplace=True)\n",
    "\n",
    "    df['CleanedHeadline'] = df['Headline'].apply(preprocess_text)\n",
    "    df['CleanedTitle'] = df['Title'].apply(preprocess_text)\n",
    "\n",
    "    headline_vectorizer = CountVectorizer(max_features=20, ngram_range=(5, 5))\n",
    "    headline_patterns = headline_vectorizer.fit(df['CleanedHeadline']).get_feature_names_out()\n",
    "\n",
    "    title_vectorizer = CountVectorizer(max_features=20, ngram_range=(3, 3))\n",
    "    title_patterns = title_vectorizer.fit(df['CleanedTitle']).get_feature_names_out()\n",
    "\n",
    "    for pattern in headline_patterns:\n",
    "        df[f'Headline_{pattern}'] = df['CleanedHeadline'].str.contains(pattern).astype(int)\n",
    "\n",
    "    for pattern in title_patterns:\n",
    "        df[f'Title_{pattern}'] = df['CleanedTitle'].str.contains(pattern).astype(int)\n",
    "\n",
    "\n",
    "    features = [\n",
    "        'Topic', 'Hour', 'Month_sin', 'Month_cos', 'Day_sin', 'Day_cos',\n",
    "        'SourceFreq', 'Sentiment_mean'] + [f'Headline_{pattern}' for pattern in headline_patterns] + [f'Title_{pattern}' for pattern in title_patterns]\n",
    "\n",
    "    X = df[features]\n",
    "    y = df['log_' + target_name]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "    X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    model = LGBMRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform and calculate metrics\n",
    "    predictions_original = np.expm1(predictions)\n",
    "    y_test_original = np.expm1(y_test)\n",
    "    mse = mean_squared_error(y_test_original, predictions_original)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_original, predictions_original)\n",
    "    return {'MSE': mse, 'RMSE': rmse, 'R-squared': r2}\n",
    "\n",
    "# Main execution (replace 'data' with your actual DataFrame)\n",
    "df = data.copy()\n",
    "targets = ['Facebook', 'GooglePlus', 'LinkedIn']\n",
    "results = {}\n",
    "\n",
    "for target in targets:\n",
    "  metrics = train_and_evaluate_lightgbm(df.copy(), target)\n",
    "  results[target] = metrics  # Store the results\n",
    "  print(f\"Results for {target} (LightGBM):\")\n",
    "  print(f\"  MSE: {metrics['MSE']:.2f}\")\n",
    "  print(f\"  RMSE: {metrics['RMSE']:.2f}\")\n",
    "  print(f\"  R-squared: {metrics['R-squared']:.2f}\")\n",
    "  print(\"-\" * 30)  # Optional separator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of all results:\n",
      "Facebook: R-squared = 0.63\n",
      "GooglePlus: R-squared = 0.70\n",
      "LinkedIn: R-squared = 0.64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary of all results:\")\n",
    "for target, metrics in results.items():\n",
    "  print(f\"{target}: R-squared = {metrics['R-squared']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Results (LightGBM):\n",
    "\n",
    "The following metrics evaluate the performance of the LightGBM models for predicting social media engagement on Facebook, GooglePlus, and LinkedIn.\n",
    "\n",
    "*   **Mean Squared Error (MSE):** Average of squared prediction errors. MSE = (1/n) * Σ(yᵢ - ŷᵢ)²\n",
    "*   **Root Mean Squared Error (RMSE):** Square root of MSE, in the same units as the target. RMSE = sqrt(MSE)\n",
    "*   **R-squared (R²):** Proportion of variance in the target explained by the model. R² = 1 - (SSres / SStot)\n",
    "\n",
    "**Facebook:**\n",
    "\n",
    "*   **MSE: 131908.46:** The average squared prediction error is 131908.46. This represents the average squared difference between the predicted and actual Facebook engagement counts.\n",
    "*   **RMSE: 363.19:** On average, the model's predictions deviate from the actual Facebook engagement counts by approximately 363.19 units. This provides a more interpretable measure of error in the original scale of the target variable.\n",
    "*   **R-squared: 0.63:** The model explains 63% of the variance in Facebook engagement. This is a significant improvement compared to previous models, suggesting the LightGBM effectively captures a substantial portion of the factors influencing Facebook engagement.\n",
    "\n",
    "**GooglePlus:**\n",
    "\n",
    "*   **MSE: 75483.17:** The average squared prediction error is 75483.17 for GooglePlus engagement.\n",
    "*   **RMSE: 274.74:** The model's predictions deviate from the actual GooglePlus engagement counts by approximately 274.74 units on average.\n",
    "*   **R-squared: 0.70:** The model explains 70% of the variance in GooglePlus engagement, indicating a strong fit and the best performance among all platforms for LightGBM.\n",
    "\n",
    "**LinkedIn:**\n",
    "\n",
    "*   **MSE: 19206.81:** The average squared prediction error for LinkedIn engagement is 19206.81. This is the lowest MSE among all platforms and models, suggesting the best prediction accuracy for LinkedIn.\n",
    "*   **RMSE: 138.59:** On average, the predictions deviate from the actual LinkedIn engagement counts by approximately 138.59 units.\n",
    "*   **R-squared: 0.64:** The model explains 64% of the variance in LinkedIn engagement. This is a strong fit and suggests the LightGBM is effective at capturing the factors influencing LinkedIn engagement.\n",
    "\n",
    "**Summary and Comparison:**\n",
    "\n",
    "LightGBM models achieve state-of-the-art performance among the evaluated models. They significantly outperform previous models in terms of R-squared for all platforms. The MSE and RMSE are also considerably lower, indicating substantially reduced prediction errors. This suggests that LightGBM's gradient boosting approach effectively captures the complex non-linear relationships within the data, leading to more accurate predictions compared to linear models, Random Forests, and even the Neural Network in this specific case. While further hyperparameter tuning could potentially improve the LightGBM's performance even further, it demonstrates the power of gradient boosting algorithms for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here's a comparison of ALL the models:\n",
    "\n",
    "| Metric      | Platform   | Neural Network | Random Forest | Linear Regression | LightGBM |\n",
    "| ----------- | ---------- | -------------- | ------------- | ----------------- |----------|\n",
    "| MSE         | Facebook   | 221839.39      | 282531.20     | 263891.36         |131908.46 |\n",
    "| RMSE        | Facebook   | 471.00         | 531.54        | 513.70            |363.19    |\n",
    "| R-squared   | Facebook   | 0.38           | 0.22          | 0.27              |0.63      |\n",
    "| MSE         | GooglePlus | 184072.60      | 218617.72     | 192194.94         |75483.17  |\n",
    "| RMSE        | GooglePlus | 429.04         | 467.57        | 438.40            |274.74    |\n",
    "| R-squared   | GooglePlus | 0.28           | 0.14          | 0.24              |0.70      |\n",
    "| MSE         | LinkedIn   | 33276.79       | 42194.76      | 34803.57          |19206.81  |\n",
    "| RMSE        | LinkedIn   | 182.42         | 205.41        | 186.56            |138.59    |\n",
    "| R-squared   | LinkedIn   | 0.37           | 0.21          | 0.35              |0.64      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>93239.000000</td>\n",
       "      <td>93239.000000</td>\n",
       "      <td>93239.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1709.134605</td>\n",
       "      <td>1799.756127</td>\n",
       "      <td>785.776226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>600.936341</td>\n",
       "      <td>505.231734</td>\n",
       "      <td>228.102370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>482.225000</td>\n",
       "      <td>441.187500</td>\n",
       "      <td>134.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1228.854167</td>\n",
       "      <td>1422.045833</td>\n",
       "      <td>579.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1540.062500</td>\n",
       "      <td>1695.366667</td>\n",
       "      <td>801.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2115.179167</td>\n",
       "      <td>2077.100000</td>\n",
       "      <td>928.319444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5763.013889</td>\n",
       "      <td>4503.333333</td>\n",
       "      <td>1975.381944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Facebook    GooglePlus      LinkedIn\n",
       "count  93239.000000  93239.000000  93239.000000\n",
       "mean    1709.134605   1799.756127    785.776226\n",
       "std      600.936341    505.231734    228.102370\n",
       "min      482.225000    441.187500    134.412500\n",
       "25%     1228.854167   1422.045833    579.208333\n",
       "50%     1540.062500   1695.366667    801.472222\n",
       "75%     2115.179167   2077.100000    928.319444\n",
       "max     5763.013889   4503.333333   1975.381944"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[targets].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we do not get the most accurate results for continous value prediction of popularity we are still able to improve and perform better than the Standard deviation of the target columns, which suggests our model is able to find patterns and make educated guess for the popularity of an article given its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personaluse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
